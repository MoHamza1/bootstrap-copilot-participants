import * as path from 'path';
import * as vscode from 'vscode';
import { ParticipantContext, ParticipantMessageMetadata, ParticipantModule } from '../../core/types';

const decodeFile = (content: Uint8Array): string => new TextDecoder('utf-8').decode(content);

const parseAnalyseCommand = (input: string): string | undefined => {
  const match = input.trim().match(/^\/analyse\s+(.+)$/i);
  return match?.[1]?.trim();
};

const ensureWorkspaceFile = (rawPath: string): vscode.Uri | undefined => {
  const workspaceFolders = vscode.workspace.workspaceFolders;
  if (!workspaceFolders || workspaceFolders.length === 0) {
    return undefined;
  }

  let candidate: vscode.Uri;
  if (rawPath.startsWith('file:')) {
    candidate = vscode.Uri.parse(rawPath);
  } else if (path.isAbsolute(rawPath)) {
    candidate = vscode.Uri.file(rawPath);
  } else {
    candidate = vscode.Uri.joinPath(workspaceFolders[0].uri, rawPath);
  }

  const workspaceFolder = vscode.workspace.getWorkspaceFolder(candidate);
  if (!workspaceFolder) {
    return undefined;
  }

  return candidate;
};

const createAnalysisOutputUri = (source: vscode.Uri, modelName: string): vscode.Uri => {
  const sanitizedModel = modelName.replace(/[^a-z0-9-_]+/gi, '-').toLowerCase() || 'model';
  const parentDir = vscode.Uri.file(path.dirname(source.fsPath));
  return vscode.Uri.joinPath(parentDir, `text-analysis-${sanitizedModel}.md`);
};

const createCodegenParticipant = (): ParticipantModule => {
  let output: vscode.OutputChannel | undefined;

  const handleFileAnalysis = async (
    targetPath: string,
    stream: vscode.ChatResponseStream
  ): Promise<string> => {
    const uri = ensureWorkspaceFile(targetPath);
    if (!uri) {
      const warning = `Unable to resolve file within the open workspace: \`${targetPath}\`.`;
      stream.markdown(`⚠️ ${warning}`);
      return warning;
    }

    let fileText: string;
    try {
      const bytes = await vscode.workspace.fs.readFile(uri);
      fileText = decodeFile(bytes);
    } catch (err) {
      const messageError = err instanceof Error ? err.message : String(err);
      const warning = `Failed to read file: ${messageError}`;
      stream.markdown(`⚠️ ${warning}`);
      return warning;
    }

    const MAX_CHARS = 20000;
    let truncated = fileText;
    if (fileText.length > MAX_CHARS) {
      truncated = fileText.slice(0, MAX_CHARS);
      stream.markdown(`ℹ️ File truncated to first ${MAX_CHARS.toLocaleString()} characters for analysis.`);
    }

    const models = await vscode.lm.selectChatModels();
    if (!models.length) {
      const warning = 'No chat models available to generate analysis.';
      stream.markdown(`⚠️ ${warning}`);
      return warning;
    }

    const model = models[0];
    const prompt = [
      'You are a senior engineer analysing a project file.',
      `Summarize the file \`${path.basename(uri.fsPath)}\` in concise bullet points describing purpose, key details, risks, and recommended next steps. Limit to 120 words.`,
      '---',
      truncated
    ].join('\n\n');

    let responseText = '';
    try {
      const response = await model.sendRequest([
        vscode.LanguageModelChatMessage.User(prompt)
      ]);

      for await (const chunk of response.text) {
        responseText += chunk;
      }
    } catch (err) {
      const messageError = err instanceof Error ? err.message : String(err);
      const warning = `Failed to analyse file: ${messageError}`;
      stream.markdown(`⚠️ ${warning}`);
      return warning;
    }

    const finalText = responseText.trim() || 'Model returned no analysis.';
    stream.markdown(`### Analysis of ${path.basename(uri.fsPath)}`);
    stream.markdown(finalText);

    try {
      const outputUri = createAnalysisOutputUri(uri, model.name ?? model.id);
      const header = `# Analysis for ${path.basename(uri.fsPath)}\n\nGenerated by ${model.name ?? model.id} on ${new Date().toISOString()}\n\n`;
      const encoder = new TextEncoder();
      await vscode.workspace.fs.writeFile(outputUri, encoder.encode(`${header}${finalText}\n`));
      stream.markdown(`✅ Saved analysis to \`${outputUri.fsPath}\`.`);
      output?.appendLine(`Analysis written to ${outputUri.fsPath}`);
    } catch (err) {
      const messageError = err instanceof Error ? err.message : String(err);
      const warning = `Failed to write analysis file: ${messageError}`;
      stream.markdown(`⚠️ ${warning}`);
      output?.appendLine(warning);
      return warning;
    }

    return 'Code generator completed analysis.';
  };

  return {
    activate(context: ParticipantContext) {
      output = context.createOutputChannel('Codegen Participant');
      output.appendLine('Code generator participant ready.');
    },
    async handleMessage(
      message: unknown,
      _context: ParticipantContext,
      stream?: vscode.ChatResponseStream,
      _metadata?: ParticipantMessageMetadata
    ) {
      output?.appendLine(`Received message: ${JSON.stringify(message)}`);
      const messageText = typeof message === 'string' ? message : JSON.stringify(message);

      if (typeof message === 'string' && stream) {
        const analyseTarget = parseAnalyseCommand(message);
        if (analyseTarget) {
          return handleFileAnalysis(analyseTarget, stream);
        }
      }

      stream?.markdown('### Code Generator');
      stream?.markdown(`Scaffolding request acknowledged for:\n\n- \`${messageText}\``);

      try {
        const models = await vscode.lm.selectChatModels();
        if (!models.length) {
          const warning = 'No chat models available to generate the poem.';
          stream?.markdown(`⚠️ ${warning}`);
          return warning;
        }

        const chat = models[0];
        const prompt =
          'Write a 50 word poem titled "The Road to Production Isn\'t Free". Return the title on the first line, followed by the poem text. Keep it exactly 50 words.';
        const response = await chat.sendRequest([vscode.LanguageModelChatMessage.User(prompt)]);

        let poem = '';
        for await (const chunk of response.text) {
          poem += chunk;
        }

        const trimmedPoem = poem.trim();
        if (trimmedPoem.length === 0) {
          const fallback = 'The language model returned an empty response.';
          stream?.markdown(`⚠️ ${fallback}`);
          return fallback;
        }

        stream?.markdown(trimmedPoem);
        return 'Code generator streamed the LLM-generated poem.';
      } catch (err) {
        const messageError = err instanceof Error ? err.message : String(err);
        const errorNote = `Failed to generate poem: ${messageError}`;
        output?.appendLine(errorNote);
        stream?.markdown(`⚠️ ${errorNote}`);
        return errorNote;
      }
    },
    dispose() {
      output?.dispose();
      output = undefined;
    }
  };
};

export const participant = createCodegenParticipant();
export default participant;
